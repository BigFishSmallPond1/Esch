Norman Esch Engineering Innovation and Entrepreneurship Award


The Idea: To create an AI powered anomaly detection system for AI threat prevention in software development firms and small-to-medium-sized businesses (SMBs).
	
Brief Addressal of the Problem: This solution targets the growing risk of security breaches within SMBs, and software development firms, which often handle sensitive data but lack the advanced security infrastructure, resources, and expertise to prevent unauthorized access. By prioritizing breach intervention, it provides a specialized, affordable tool designed to monitor and safeguard critical assets like intellectual property, and client information. Time is of the essence when it comes to detecting security breaches-the earlier a breach is identified, the better the chances of preventing significant damage. Rapid detection, and response can stop a breach before it escalates, minimizing operational, financial and reputational harm to the business.

Target Demographic (need statistics about market size and so forth): This solution can target a range of industries, including software development firms, tech startups, and small-to-medium-sized businesses (SMBs) that handle sensitive information but lack advanced security against threats posed to their AI systems. Additional markets include healthcare, legal, financial services, creative agencies, and consulting firms. Sectors like education, government contractors, e-commerce, R&D, and non-profits also stand to benefit, especially where safeguarding intellectual property, client information, or proprietary data accessible to AI is critical.

Deeper Analysis of the Problem: 
	1.  Affected Parties?
		The primary victims of security breaches are consumers who use the services and products of affected organizations, and 		those organizations themselves. In the case of individuals, breaches may expose, steal, or misuse personal information, 		financial data, or private communications, often due to malicious actions by insiders or outsiders, or negligent actions 		by insiders within the company. In the case of companies, breaches can lead to the loss of sensitive data, intellectual 		property, financial harm, operational disruptions, and significant reputational damage.
 	2. Why Does this Problem Exist?
		The primary risk to AI systems arises from malicious actors attempting to gain unauthorized access to sensitive or 			critical information or using AI in a way that exploits its capabilities for harmful purposes. The root causes that may 		facilitate these threats include:
			*    Inherent Vulnerabilities in Software and Security Systems: AI systems are built on complex software that 				     often contains exploitable flaws such as bugs, insecure configurations, or outdated components. Attackers 				     frequently exploit these vulnerabilities to infiltrate systems or manipulate AI outputs. The situation 				     worsens with the rapidly evolving nature of AI systems, leading to increasingly convoluted codebases that 				     become more prone to errors and security vulnerabilities that can easily go undetected. These inherent 				     security weaknesses not only jeopardize the AI system itself but can also serve as entry points for attackers 			     to access other parts of the network, potentially leading to broader compromises within the organization's 			     infrastructure
			*    AI Advancement Outpacing Regulation and Lack of Skilled Talent: As AI technology evolves rapidly, security 			     regulations often lag behind, creating a regulatory gap that leaves AI systems vulnerable to exploitation by 			     malicious actors who can leverage software flaws or underdeveloped security standards to breach systems. 				     Compounding this issue is the shortage of AI security professionals, which exacerbates these risks. Without 			     specialized talent, organizations may inadvertently overlook vulnerabilities within their AI systems, further 			     creating openings for malicious actors to exploit.
		The abuse of the aforementioned vulnerabilities often manifests through tactics such as:	
			*    Prompt Injection This breach occurs when hackers craft malicious inputs that mimic legitimate prompts, 				     exploiting both generative and non-generative AI systems to leak sensitive information, spread 					     misinformation, or cause harm. For instance, a malicious actor could manipulate a large language model (LLM) 			     to indirectly request ingredients for napalm by framing it as an academic inquiry. Additionally, prompt 				     injection can generate false reports or misleading content, complicating the challenge of distinguishing 				     between genuine and deceptive information.
			*    API Integrations: AI services from cloud providers often rely on external APIs that can access sensitive 				     information, such as user data and financial records. A notable example is the July 2019 Capital One data 				     breach, which affected over 100 million customer records. Due to a misconfigured Web Application Firewall 				     (WAF), an attacker exploited vulnerabilities to access sensitive data on AWS, impacting Capital One's AI-				     driven credit monitoring system that relied on these compromised APIs for risk analysis and monitoring
			*    DDoS: This breach occurs when hackers overwhelm services with pointless connection attempts, which can 				     significantly impact both generative and non-generative AI systems like so:
			*    Performance Degradation and Service Disruption: AI systems can experience severe slowdowns during DDoS 				     attacks, rendering key features inaccessible. In 2023, Google Cloud faced a record DDoS attack of 398 million 			     requests per second, targeting services that utilize AI for tasks like natural language processing and 				     machine learning. This overwhelming volume caused significant performance degradation, leading to delays and 			     interruptions in AI applications for many clients relying on Google's infrastructure for real-time data 				     processing and analytics
			*    Increased Costs: DDoS attacks can significantly raise computational costs for processing and mitigation, 				     impacting the cost-efficiency of generative AI services. In August 2023, OpenAI's ChatGPT API faced a massive 			     DDoS attack that disrupted services and incurred millions in mitigation and security enhancement costs. The    			     recovery process took weeks as OpenAI worked to restore operations and strengthen defenses

Ultimately, these techniques result in the erosion of trust in both public and private sectors and undermine public confidence, affecting AI's long-term perception.

How will you solve the problem: The solution to a problem of this magnitude is often multi-faceted. After conducting extensive research, we have identified significant flaws in the current day approaches to these security vulnerabilities and plan to address them one by one in the following manners:
	*    Prompt Injection: To solve this issue, we will develop an advanced anomaly detection system that integrates multiple 		     proprietary models based on the latest research in prompt injection techniques. This unique approach enhances context-		     awareness by combining contextual understanding with sequential analysis to identify suspicious patterns indicative of prompt 	     injection attempts. The system will recognize specific entities and keywords linked to malicious inputs, improving its 	   	     ability to flag harmful content. A robust framework will analyze input semantics and structure, distinguishing normal user 	     behavior from anomalies while capturing temporal dependencies in user interactions to identify unusual input sequences. This 	     proactive system will continually learn from user interactions to adapt to evolving threats and in response to flags it will 	     dynamically sanitize content and implement throttling or blocking mechanisms to limit further actions from attackers, 	   	     minimizing potential damage while preserving legitimate user sessions
	*    API Integration: To tackle vulnerabilities in API integrations, we will develop a robust anomaly detection system that 	   	     utilizes proprietary models to analyze API traffic patterns and identify malicious activities in real time. The system will 	     focus on detecting suspicious patterns, such as unusual spikes in request frequency or atypical response times. Beyond 	   	     identification, it will implement automated responses to trigger predefined security protocols, ensuring swift containment of 	     threats. For innovation's sake, there will be adaptive learning capabilities,  meaning the system will evolve with changing 	     traffic patterns and emerging threats. By employing advanced feature engineering techniques, we will extract meaningful 	   	     insights from traffic data, such as user behavior profiles and session characteristics. When anomalies are identified, the 	     system will alert security teams and initiate automated remediation processes, like throttling suspicious IPs or enforcing 	     stricter access controls.   DDoS: To address the evolving threat of DDoS attacks, we will develop an AI-powered honeypot 	   	     system that revolutionizes network defense. Honeypots are decoy systems designed to attract malicious traffic away from 	   	     critical infrastructure while providing insights into attack methods. Our dynamic, AI-based honeypots will continuously learn 	     from ongoing attacks, adapting their behavior in real time to better mimic genuine vulnerabilities and deceive attackers. 	  	     This allows the system to gather critical data on attack patterns, automatically adjusting honeypot configurations to enhance 	     their effectiveness. By integrating AI, our honeypots serve as innovative active learning systems that refine their ability 	     to detect, deflect, and understand DDoS attacks, ensuring networks remain resilient against emerging threats.

All of the above solutions will be packaged within a single software suite designed for easy integration by SMBs and software development firms.

Why Did You Choose to Solve This Problem?

I chose to tackle this problem because, during my software development experience, I witnessed the severe impact of security threats like prompt injection and DDoS attacks on AI projects, jeopardizing application integrity and user trust. A close friend's AI startup suffered a debilitating DDoS attack, underscoring the vulnerabilities faced by small-to-medium-sized businesses. This motivated me to create a solution that addresses these security challenges and empowers organizations to protect their systems proactively, allowing them to focus on innovation without fear of cyber threats.

How is the problem solved today?
Today, threats like prompt injection and DDoS attacks are addressed by various solutions, including traditional security tools like Web Application Firewalls (WAFs) used by companies like Cloudflare and Intrusion Detection Systems (IDS) from organizations like Cisco. While these tools offer some protection, they often rely on signature-based detection, making them less effective against new or evolving attacks. Many small-to-medium-sized businesses (SMBs) lack the resources to implement and maintain these systems, resulting in security gaps. Alternatives like manual monitoring and incident response teams are resource-intensive and slow to react. Security consulting firms, such as Mandiant, can assess vulnerabilities but often provide costly, non-continuous protection. What sets our solution apart is its innovative, cost-effective anomaly detection using proprietary machine learning models tailored for real-time threat prevention. Our closed-loop feedback system not only detects threats but also learns and adapts over time, ensuring continuous improvement. This proactive, automated approach makes advanced AI security accessible and effective for SMBs, addressing their unique challenges in ways that existing solutions do not.

What do you plan to do next?
 Over the next four months, we plan to conduct extensive primary market research by setting up face-to-face meetings with small-to-medium-sized businesses (SMBs) and software development firms, primarily in Ontario. Our goal is to validate the specific problems related to AI threats, such as prompt injection and DDoS attacks, and to refine our solution accordingly. We will reach out to prospective contacts through phone calls, emails, and in-person meetings, leveraging resources like iBoost to connect with relevant companies. We plan to contact Rajiv Gupta, Head of the Canadian Centre for Cyber Security, to gain a deeper understanding of how AI threats, such as prompt injection and DDoS attacks, occur and evolve. His expertise will provide us with valuable insights into the current landscape of cybersecurity, helping us refine our approach and ensure that our anomaly detection system effectively addresses the most pressing vulnerabilities faced by businesses today. Additionally, we will reach out to industry professionals including Rushdi Alsaleh and Keng Hin Cheong, both AI experts, along with John Chen, an IT Specialist. These conversations will allow us to gather insights into their experiences with cybersecurity threats and their specific needs for an effective anomaly detection system. Engaging with these experts will also enable us to conduct a thorough technical analysis of our project design, ensuring that we receive actionable recommendations for optimization. Winning Stage 1 of the ESCH Award would provide us with the resources needed to complete the deliverables for Stage 2, including proof of customer validation, competitive advantage, a unique selling proposition, and a feasibility study. The funding from this award would enable us to dedicate our time to developing our solution, cover transportation and accommodation costs for meetings, create impactful presentations, and compile comprehensive market and feasibility reports.

Inherent Risks?
We could encounter several technical challenges along the way, including suboptimal machine learning performance, difficulties with data scraping, and the need to accurately analyze and classify data. Significant risks also exist, such as our target customers not fully appreciating the value of our solution, launching the product at the right time, and failing to deliver on our performance promises.
To address these challenges, we will closely align our development process with customer feedback through thorough primary research. We will also be employing agile methodologies will help us monitor progress and tap into domain expertise as needed to ensure we meet our performance benchmarks. By leveraging proprietary data and unique AI models, we aim to create a closed-loop feedback solution that stands apart from competitors. We are also ready to adapt our approach based on customer insights and changing needs.


Benefit to Canada?
Our solution not only enhances cybersecurity but also promotes economic growth by creating job opportunities in the tech sector, particularly in AI and cybersecurity. As we empower small and medium-sized businesses (SMBs) with accessible AI-driven security, these organizations can operate more efficiently, increase profitability, and reinvest in innovation. This ripple effect strengthens economic diversity and resilience, enabling SMBs to compete effectively and contribute to community development.
The creation of jobs in these high-demand fields also has significant social benefits. By fostering a skilled workforce, we help to reduce unemployment and provide individuals with career pathways that offer stability and growth. As these jobs emerge, they contribute to the overall well-being of communities, encouraging local investment and fostering a culture of innovation. In this way, our solution aligns with Canada's economic objectives while promoting social progress and empowerment.

Feasibility?
Our AI-driven anomaly detection system is designed with a solid technological framework that ensures feasibility and effectiveness in addressing cybersecurity threats. Central to our solution are proprietary machine learning models grounded in the latest research, specifically tailored to detect and respond to threats like DDoS attacks, API integrations and prompt injection. These models leverage a variety of data sources, including network traffic patterns, historical attack data, and user behavior analytics, which we collect through industry-standard data mining techniques.

To build our models, we will implement a multi-layered data collection algorithm that scrapes and aggregates data from various sources. This approach will not only provide a comprehensive dataset but also ensure diversity in the types of data collected, enhancing the models' robustness. The data will then undergo rigorous cleaning and transformation processes to create structured features, ensuring that quality issues are addressed early and any biases in the data are mitigated. We will employ statistical tests to validate the integrity of our datasets, enabling us to train models that produce reliable and explainable results.

Our solution features a closed-loop system that continuously learns and adapts based on real-time feedback. As the AI detects anomalies, it will refine its models using feedback mechanisms that incorporate key performance indicators (KPIs) from past security incidents and responses. This iterative learning process allows our system to improve its detection capabilities over time, making it increasingly effective at identifying new and evolving threats.
In terms of technology infrastructure, we will utilize cloud-based services from leading providers such as AWS or Google Cloud. These platforms offer scalable storage and processing power, allowing us to handle large volumes of data without significant upfront investment. Our solution will also incorporate advanced analytics services, enabling us to implement real-time monitoring and reporting features that keep stakeholders informed of potential threats.
Additionally, we will leverage open-source tools and frameworks, such as Python, TensorFlow, and Scikit-learn, for model development and deployment. This approach not only minimizes costs but also accelerates the development process by utilizing well-established libraries and resources. By combining proprietary machine learning models with accessible technologies, our solution not only meets the current cybersecurity challenges but also positions itself to evolve as new threats emerge, ensuring long-term viability and effectiveness.


